# llm-model-playground-server
This serves as a server for the LLM Model Playground frontend app

## How to Run

### 1. Prerequisites
- Python 3.8+
- An [OpenAI API Key](https://platform.openai.com/api-keys)
- An [Anthropic API Key](https://console.anthropic.com/dashboard)
- An [xAI (Grok) API Key](https://x.ai/)

### 2. Setup

Clone the repository and navigate into the project directory.

#### Create a Virtual Environment
It's highly recommended to use a virtual environment to manage dependencies.
```bash
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`
```

#### Install Dependencies
Install all the required packages using the `requirements.txt` file.
```bash
pip install -r requirements.txt
```

#### Configure Environment Variables
The application uses a `.env` file to manage API keys. Create a file named `.env` in the root of the project directory and add your OpenAI API key to it:
```
OPENAI_API_KEY="your_openai_api_key_here"
```
> **Note:** The services for Anthropic and xAI are currently simulated and do not require API keys yet.

### 3. Run the Server
You can run the server directly using Python. It will be accessible at `http://127.0.0.1:8000`.
```bash
fastapi dev server.py
```
OR
```bash
uvicorn server:app --host=0.0.0.0 --port=8000
```
The server is configured to auto-reload when you make changes to the code, making development easier.

### 4. Test the API
Once the server is running, you can access the interactive API documentation generated by FastAPI at `http://127.0.0.1:8000/docs`.
